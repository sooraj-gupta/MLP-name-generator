{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06773d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "66910de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aphrodite',\n",
       " 'apollo',\n",
       " 'ares ',\n",
       " 'artemis ',\n",
       " 'athena  ',\n",
       " 'hephaestus',\n",
       " 'hestia  ']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#names.txt contains Arabic, Indian, Greek, and American Names\n",
    "words = open('names.txt','r').read().splitlines() \n",
    "words[-10:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc22ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48358"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "896320e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '.', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set((''.join(words)).lower())))\n",
    "# chars[0], chars[2] = chars[2], chars[0]\n",
    "# chars.insert(0,'.')\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1123a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    context = [stoi['.']] * block_size\n",
    "    for ch in w.lower() + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "    \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3e674c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = 300\n",
    "embDims = 5\n",
    "\n",
    "C = torch.randn((len(itos),embDims))\n",
    "W1 = torch.randn((embDims*block_size,neurons)) * 0.01\n",
    "b1 = torch.randn(neurons)* 0.01\n",
    "W2 = torch.randn((neurons,len(itos))) * 0.01\n",
    "b2 = torch.randn(len(itos)) * 0\n",
    "params = [C,W1,b1,W2,b2]\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fded0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5b7c04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss():\n",
    "    emb = C[X] #32x3x2\n",
    "    h = torch.tanh(emb.view(emb.shape[0],embDims*block_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits,Y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2caf79a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 1.948021411895752\n",
      "1000 -> 1.9614207744598389\n",
      "2000 -> 2.038947343826294\n",
      "3000 -> 2.008090019226074\n",
      "4000 -> 2.0818777084350586\n",
      "5000 -> 2.090620279312134\n",
      "6000 -> 2.001598834991455\n",
      "7000 -> 1.9292336702346802\n",
      "8000 -> 2.0200302600860596\n",
      "9000 -> 2.022744655609131\n",
      "10000 -> 1.920793056488037\n",
      "11000 -> 1.9705742597579956\n",
      "12000 -> 2.025944948196411\n",
      "13000 -> 2.0747344493865967\n",
      "14000 -> 2.1247143745422363\n",
      "15000 -> 1.9978214502334595\n",
      "16000 -> 2.0200507640838623\n",
      "17000 -> 1.9554550647735596\n",
      "18000 -> 2.1442532539367676\n",
      "19000 -> 1.9627459049224854\n",
      "20000 -> 1.9882065057754517\n",
      "21000 -> 1.9713928699493408\n",
      "22000 -> 2.0115978717803955\n",
      "23000 -> 2.0509579181671143\n",
      "24000 -> 1.9677590131759644\n",
      "25000 -> 2.0512852668762207\n",
      "26000 -> 1.9124013185501099\n",
      "27000 -> 2.0761404037475586\n",
      "28000 -> 1.9191193580627441\n",
      "29000 -> 1.9411853551864624\n",
      "30000 -> 2.0313971042633057\n",
      "31000 -> 1.952857494354248\n",
      "32000 -> 1.9418389797210693\n",
      "33000 -> 1.9694241285324097\n",
      "34000 -> 2.149663209915161\n",
      "35000 -> 2.076702356338501\n",
      "36000 -> 1.9331212043762207\n",
      "37000 -> 2.0638647079467773\n",
      "38000 -> 2.0812861919403076\n",
      "39000 -> 2.0607399940490723\n",
      "40000 -> 2.0065836906433105\n",
      "41000 -> 2.0185229778289795\n",
      "42000 -> 1.992887020111084\n",
      "43000 -> 1.9794726371765137\n",
      "44000 -> 2.02302885055542\n",
      "45000 -> 1.902466058731079\n",
      "46000 -> 2.033780336380005\n",
      "47000 -> 2.1083383560180664\n",
      "48000 -> 1.9976731538772583\n",
      "49000 -> 2.09580397605896\n",
      "2.0247747898101807\n"
     ]
    }
   ],
   "source": [
    "## TRAINING ##\n",
    "n = 50000\n",
    "lr = 0.001\n",
    "for i in range(n):\n",
    "    \n",
    "    #forward pass\n",
    "    ix = torch.randint(0,X.shape[0], (512,))\n",
    "    small = X[ix]\n",
    "    emb = C[small]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],embDims*block_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits,Y[ix])\n",
    "    \n",
    "    #backward pass\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    if( i % (n/50) == 0):\n",
    "        emb = C[X] #32x3x2\n",
    "        print( i, \"->\", loss.item())\n",
    "        \n",
    "    #update\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "print( get_loss() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c49a87e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0247747898101807"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "870d9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(start_context=None, max_length=10):\n",
    "    if start_context is None:\n",
    "        start_context = [stoi['.']] * block_size \n",
    "    else:\n",
    "        start_context = [stoi[ch] for ch in start_context]\n",
    "\n",
    "    context = start_context\n",
    "    generated_name = [itos[s] for s in start_context if s != stoi['.']]\n",
    "    for _ in range(max_length):\n",
    "        # Create the input tensor from the current context\n",
    "        context_tensor = torch.tensor(context).unsqueeze(0)  # shape (1, block_size)\n",
    "        emb = C[context_tensor]  # shape (1, block_size, 2)\n",
    "        \n",
    "        # forward pass\n",
    "        h = torch.tanh(emb.view(emb.shape[0], -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        \n",
    "        # softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # sample from the distribution\n",
    "        next_char_index = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        # append the generated character to the result\n",
    "        generated_name.append(itos[next_char_index])\n",
    "        \n",
    "        # update the context\n",
    "        context = context[1:] + [next_char_index]\n",
    "        \n",
    "        # terminate if the generated character is the period\n",
    "        if itos[next_char_index] == '.':\n",
    "            break\n",
    "\n",
    "    return ''.join(generated_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1adfedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 .  saman.\n",
      "   2 .  safaa.\n",
      "   3 .  samarie.\n",
      "   4 .  sayana.\n",
      "   5 .  saklia.\n"
     ]
    }
   ],
   "source": [
    "START_CONTEXT = \"sa\"\n",
    "num_generations = 5\n",
    "\n",
    "inp = START_CONTEXT.rjust(block_size, \".\")\n",
    "for i in range(num_generations):\n",
    "    print(f'{i+1:4d}',\". \", generate_name(start_context=list(inp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
